{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0as6T4DjqEtZ"
   },
   "source": [
    "SRCNN(Super Resolution CNN)\n",
    "```\n",
    "input : low img --> Y\n",
    "로직 : cnn을 주로 이용, Y는 일반적으로 X를 다운샘플링하고 노이즈가 섞인 형태\n",
    "output : high img --> X\n",
    "```\n",
    "구조\n",
    "```\n",
    "3개의 합성곱층\n",
    "1. Patch Extaction and Representation\n",
    "  입력 이미지에서 작은 패치를 추출해서 이 패치의 특징을 표현\n",
    "2. Non-Linear Mapping\n",
    "  추출한 패치 특징을 더 복잡한 고해상도 패치 공간으로 매핑\n",
    "3. Resolution\n",
    "  매핑된 고차원 특징을 다시 고해상도 이미지공간으로 변환  \n",
    "```\n",
    "학습과정\n",
    "```\n",
    "손실함수 : 평균제곱오차\n",
    "SRCNN : end to end 방식  저해상도 입력에서 바로 고해상도 출력을 생성\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: tqdm, PySocks, gdown\n",
      "Successfully installed PySocks-1.7.1 gdown-5.2.0 tqdm-4.67.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 공유링크를 통해 다운로드\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileURLRetrievalError",
     "evalue": "Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttp://drive.google.com/uc?id=17c7kMwVpIm6PqPE3GqJ2Pp7C07Cbg_TL\n\nbut Gdown can't. Please check connections and permissions.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileURLRetrievalError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/gdown/download.py:267\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     url = \u001b[43mget_url_from_gdrive_confirmation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/gdown/download.py:53\u001b[39m, in \u001b[36mget_url_from_gdrive_confirmation\u001b[39m\u001b[34m(contents)\u001b[39m\n\u001b[32m     52\u001b[39m         error = m.groups()[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(error)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url:\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgdown\u001b[39;00m\n\u001b[32m      4\u001b[39m file_id = \u001b[33m'\u001b[39m\u001b[33m17c7kMwVpIm6PqPE3GqJ2Pp7C07Cbg_TL\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mgdown\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp://drive.google.com/uc?id=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/gdown/download.py:278\u001b[39m, in \u001b[36mdownload\u001b[39m\u001b[34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    269\u001b[39m         message = (\n\u001b[32m    270\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFailed to retrieve file url:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    271\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou may still be able to access the file from the browser:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    276\u001b[39m             url_origin,\n\u001b[32m    277\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(message)\n\u001b[32m    280\u001b[39m filename_from_url = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    281\u001b[39m last_modified_time = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mFileURLRetrievalError\u001b[39m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttp://drive.google.com/uc?id=17c7kMwVpIm6PqPE3GqJ2Pp7C07Cbg_TL\n\nbut Gdown can't. Please check connections and permissions."
     ]
    }
   ],
   "source": [
    "# : https://drive.google.com/file/d/17c7kMwVpIm6PqPE3GqJ2Pp7C07Cbg_TL/view?usp=sharing\n",
    "# 직접다운로드\n",
    "import gdown\n",
    "file_id = '17c7kMwVpIm6PqPE3GqJ2Pp7C07Cbg_TL'\n",
    "gdown.download(f'http://drive.google.com/uc?id={file_id}',quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4YtCs14Xrx9Q"
   },
   "outputs": [],
   "source": [
    "# 압축 해제\n",
    "import zipfile\n",
    "import os\n",
    "zip_path = './SRCNN_SS.zip'\n",
    "extract_path = './SRCNN'\n",
    "with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "    z.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting albumentations\n",
      "  Using cached albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch)\n",
      "  Using cached triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting setuptools>=40.8.0 (from triton==3.3.0->torch)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting scipy>=1.10.0 (from albumentations)\n",
      "  Using cached scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting PyYAML (from albumentations)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting albucore==0.0.24 (from albumentations)\n",
      "  Using cached albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
      "  Using cached stringzilla-3.12.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
      "  Using cached simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (66 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "Using cached torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "Using cached torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
      "Using cached torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "Using cached albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
      "Using cached albucore-0.0.24-py3-none-any.whl (15 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (632 kB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached stringzilla-3.12.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "Installing collected packages: stringzilla, simsimd, pytz, nvidia-cusparselt-cu12, mpmath, tzdata, typing-extensions, tqdm, sympy, six, setuptools, PyYAML, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, annotated-types, typing-inspection, triton, scipy, python-dateutil, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, pydantic, pandas, nvidia-cusolver-cu12, albucore, torch, albumentations, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: stringzilla\n",
      "\u001b[2K    Found existing installation: stringzilla 3.12.5\n",
      "\u001b[2K    Uninstalling stringzilla-3.12.5:\n",
      "\u001b[2K      Successfully uninstalled stringzilla-3.12.5[0m \u001b[32m 0/46\u001b[0m [stringzilla]\n",
      "\u001b[2K  Attempting uninstall: simsimd━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/46\u001b[0m [stringzilla]\n",
      "\u001b[2K    Found existing installation: simsimd 6.2.10m \u001b[32m 0/46\u001b[0m [stringzilla]\n",
      "\u001b[2K    Uninstalling simsimd-6.2.1:━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/46\u001b[0m [stringzilla]\n",
      "\u001b[2K      Successfully uninstalled simsimd-6.2.1━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/46\u001b[0m [simsimd]\n",
      "\u001b[2K  Attempting uninstall: pytz━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/46\u001b[0m [simsimd]\n",
      "\u001b[2K    Found existing installation: pytz 2025.2━━━━━━━━━\u001b[0m \u001b[32m 1/46\u001b[0m [simsimd]\n",
      "\u001b[2K    Uninstalling pytz-2025.2:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/46\u001b[0m [simsimd]\n",
      "\u001b[2K      Successfully uninstalled pytz-2025.2━━━━━━━━━━━\u001b[0m \u001b[32m 1/46\u001b[0m [simsimd]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/46\u001b[0m [pytz]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.3━\u001b[0m \u001b[32m 2/46\u001b[0m [pytz]\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.3:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/46\u001b[0m [pytz]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3━━━\u001b[0m \u001b[32m 2/46\u001b[0m [pytz]\n",
      "\u001b[2K  Attempting uninstall: mpmath━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/46\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: mpmath 1.3.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/46\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling mpmath-1.3.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/46\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled mpmath-1.3.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/46\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: tzdata━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/46\u001b[0m [mpmath]arselt-cu12]\n",
      "\u001b[2K    Found existing installation: tzdata 2025.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/46\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling tzdata-2025.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/46\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled tzdata-2025.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/46\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/46\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.13.2━━━━━\u001b[0m \u001b[32m 5/46\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.13.2:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/46\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.13.2━━━━━━━━━━━\u001b[0m \u001b[32m 6/46\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/46\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/46\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/46\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/46\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: sympy[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/46\u001b[0m [tqdm]tensions]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/46\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/46\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/46\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: sixm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/46\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: six 1.17.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/46\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling six-1.17.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/46\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/46\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/46\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0━━━━━━━━━━━━\u001b[0m \u001b[32m 9/46\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/46\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: PyYAML\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.2:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.2━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: pillowm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: pillow 11.2.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling pillow-11.2.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.2.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/46\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/46\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.77━━━━━\u001b[0m \u001b[32m12/46\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/46\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.77━━━━━━━\u001b[0m \u001b[32m12/46\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/46\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\u001b[0m \u001b[32m12/46\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.6.85:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/46\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85━━\u001b[0m \u001b[32m12/46\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/46\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2━━━━━━\u001b[0m \u001b[32m14/46\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/46\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2━━━━━━━━\u001b[0m \u001b[32m14/46\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/46\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77━\u001b[0m \u001b[32m15/46\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/46\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77━━━\u001b[0m \u001b[32m15/46\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/46\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufile-cu12 1.11.1.6━━\u001b[0m \u001b[32m16/46\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufile-cu12-1.11.1.6:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/46\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6━━━━\u001b[0m \u001b[32m16/46\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/46\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77m \u001b[32m16/46\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:━━━━━━━━━━━━\u001b[0m \u001b[32m16/46\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77[0m \u001b[32m16/46\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/46\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77[0m \u001b[32m18/46\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/46\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77━\u001b[0m \u001b[32m18/46\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/46\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80[0m \u001b[32m19/46\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/46\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80━\u001b[0m \u001b[32m19/46\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu120m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/46\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1━━\u001b[0m \u001b[32m20/46\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/46\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1━━━━\u001b[0m \u001b[32m20/46\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: numpym\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/46\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/46\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/46\u001b[0m [numpy]las-cu12]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/46\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: networkx[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/46\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: networkx 3.4.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/46\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling networkx-3.4.2:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/46\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled networkx-3.4.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/46\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/46\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.2━━━━━━━━━━━━━\u001b[0m \u001b[32m23/46\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.2:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/46\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/46\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: fsspec90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/46\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: filelock1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: filelock 3.18.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling filelock-3.18.0:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.18.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: annotated-types\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: annotated-types 0.7.0━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling annotated-types-0.7.0:\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled annotated-types-0.7.0━━━━━━━━━━\u001b[0m \u001b[32m25/46\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: typing-inspection\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/46\u001b[0m [annotated-types]\n",
      "\u001b[2K    Found existing installation: typing-inspection 0.4.1━━━━━━\u001b[0m \u001b[32m27/46\u001b[0m [annotated-types]\n",
      "\u001b[2K    Uninstalling typing-inspection-0.4.1:\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/46\u001b[0m [annotated-types]\n",
      "\u001b[2K      Successfully uninstalled typing-inspection-0.4.1━━━━━━━━\u001b[0m \u001b[32m27/46\u001b[0m [annotated-types]\n",
      "\u001b[2K  Attempting uninstall: tritonm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/46\u001b[0m [annotated-types]\n",
      "\u001b[2K    Found existing installation: triton 3.3.0m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/46\u001b[0m [annotated-types]\n",
      "\u001b[2K    Uninstalling triton-3.3.0:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/46\u001b[0m [annotated-types]\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.090m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/46\u001b[0m [annotated-types]\n",
      "\u001b[2K  Attempting uninstall: scipy━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/46\u001b[0m [triton]ypes]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.390m━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/46\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling scipy-1.15.3:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/46\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.3╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m30/46\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: python-dateutil[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m30/46\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0━━\u001b[0m \u001b[32m30/46\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m30/46\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0━━━━\u001b[0m \u001b[32m30/46\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: pydantic-core0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m30/46\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.33.2━━━━━━━━━\u001b[0m \u001b[32m30/46\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling pydantic_core-2.33.2:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m30/46\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.33.290m━━━━━━━━━━━━\u001b[0m \u001b[32m32/46\u001b[0m [pydantic-core]\n",
      "\u001b[2K  Attempting uninstall: opencv-python-headless[90m━━━━━━━━━━━━\u001b[0m \u001b[32m32/46\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Found existing installation: opencv-python-headless 4.11.0.86m \u001b[32m32/46\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Uninstalling opencv-python-headless-4.11.0.86:━━━━━━━━━━━━\u001b[0m \u001b[32m32/46\u001b[0m [pydantic-core]\n",
      "\u001b[2K      Successfully uninstalled opencv-python-headless-4.11.0.86[0m \u001b[32m32/46\u001b[0m [pydantic-core]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m33/46\u001b[0m [opencv-python-headless]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\u001b[0m \u001b[32m33/46\u001b[0m [opencv-python-headless]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:[90m━━━━━━━━━━━\u001b[0m \u001b[32m33/46\u001b[0m [opencv-python-headless]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2━━\u001b[0m \u001b[32m33/46\u001b[0m [opencv-python-headless]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4━━━\u001b[0m \u001b[32m34/46\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4━━━━━\u001b[0m \u001b[32m34/46\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m35/46\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.5.1.17━━━\u001b[0m \u001b[32m35/46\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m35/46\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17━━━━━\u001b[0m \u001b[32m35/46\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: jinja2━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m36/46\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m36/46\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m36/46\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.6m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m36/46\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: pydantic━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m36/46\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: pydantic 2.11.5m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m36/46\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling pydantic-2.11.5:━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m38/46\u001b[0m [pydantic]cu12]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.11.5╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m38/46\u001b[0m [pydantic]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m38/46\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: pandas 2.2.3m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m38/46\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling pandas-2.2.3:━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m39/46\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.2.391m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m39/46\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m39/46\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\u001b[0m \u001b[32m39/46\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m39/46\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2━━\u001b[0m \u001b[32m39/46\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: albucore━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: albucore 0.0.24\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling albucore-0.0.24:━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled albucore-0.0.24m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.7.091m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m40/46\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.7.0:━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m42/46\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.0━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m42/46\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: albumentations━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m42/46\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: albumentations 2.0.8m\u001b[90m━━━\u001b[0m \u001b[32m42/46\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling albumentations-2.0.8:━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m42/46\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled albumentations-2.0.8[0m\u001b[90m━━━\u001b[0m \u001b[32m42/46\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m43/46\u001b[0m [albumentations]\n",
      "\u001b[2K    Found existing installation: torchvision 0.22.0\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m43/46\u001b[0m [albumentations]\n",
      "\u001b[2K    Uninstalling torchvision-0.22.0:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m43/46\u001b[0m [albumentations]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.22.0m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m43/46\u001b[0m [albumentations]\n",
      "\u001b[2K  Attempting uninstall: torchaudio━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m44/46\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.7.00m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m44/46\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.7.0:━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m44/46\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.7.0[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m44/46\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/46\u001b[0m [torchaudio]rchaudio]ision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 albucore-0.0.24 albumentations-2.0.8 annotated-types-0.7.0 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 opencv-python-headless-4.11.0.86 pandas-2.2.3 pillow-11.2.1 pydantic-2.11.5 pydantic-core-2.33.2 python-dateutil-2.9.0.post0 pytz-2025.2 scipy-1.15.3 setuptools-80.9.0 simsimd-6.2.1 six-1.17.0 stringzilla-3.12.5 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 tqdm-4.67.1 triton-3.3.0 typing-extensions-4.13.2 typing-inspection-0.4.1 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --force-reinstall numpy pandas opencv-python-headless torch torchvision torchaudio albumentations tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RS6AQO-_tFbG",
    "outputId": "4ece0f77-29e0-4fb4-f30c-db1a9ebdf9ec"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset ,DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import albumentations as A  # 데이터 증강 라이브러리\n",
    "from albumentations.pytorch.transforms import ToTensorV2  # 이미지 데이터를 tensor\n",
    "# 사전 학습 모델  ResNet EfficientNet등..\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Bf1bOn_WvqG6"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KYNtzICCv1bD"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xoTBmmy4v5Ki"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 2048\n",
    "EPOCHS=30\n",
    "LEARING_RATE=1e-4  #0.0001\n",
    "BATCH_SIZE=12\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wyBHVyHXwK2y"
   },
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "train_df = pd.read_csv('./SRCNN/SRCNN/train.csv')\n",
    "test_df = pd.read_csv('./SRCNN/SRCNN/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vq8EWTkiafr0",
    "outputId": "6245a65e-df5e-4b81-c0ac-3d39f5de3acd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0000.png', '0010.png')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "filenames = [files.split('/')[-1] for files in glob('./SRCNN/SRCNN/train/hr/*.*',recursive=True)]\n",
    "filenames = sorted(filenames)\n",
    "filenames[0], filenames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "kq-idJf0xsIy"
   },
   "outputs": [],
   "source": [
    "# 실제 이미지데이터가 900번까지 존재\n",
    "train_df = train_df.iloc[:11]\n",
    "test_df = test_df.iloc[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "3JF0D5qyiJHF",
    "outputId": "6feddfdf-8801-40c1-c140-102cc1b3b082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./SRCNN/SRCNN/train/lr/0000.png'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./SRCNN/SRCNN'+train_df['LR'][0][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "p7oLyJyF2Kmz"
   },
   "outputs": [],
   "source": [
    "# csv의 파일경로와 실제 경로를 매칭\n",
    "import os\n",
    "train_df['LR'] = train_df['LR'].apply(lambda x: './SRCNN/SRCNN' + x[1:])\n",
    "train_df['HR'] = train_df['HR'].apply(lambda x: './SRCNN/SRCNN' + x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "Owd0ZlYjaOnj",
    "outputId": "3bba6b6f-346a-4712-a45d-c9cced426b32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./SRCNN/SRCNN/train/lr/0000.png</td>\n",
       "      <td>./SRCNN/SRCNN/train/hr/0000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./SRCNN/SRCNN/train/lr/0001.png</td>\n",
       "      <td>./SRCNN/SRCNN/train/hr/0001.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                LR                               HR\n",
       "0  ./SRCNN/SRCNN/train/lr/0000.png  ./SRCNN/SRCNN/train/hr/0000.png\n",
       "1  ./SRCNN/SRCNN/train/lr/0001.png  ./SRCNN/SRCNN/train/hr/0001.png"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Umgn7C8jyAjp"
   },
   "outputs": [],
   "source": [
    "# 데이터셋\n",
    "# 타입힌트 적용\n",
    "class SRDataset(Dataset):\n",
    "  def __init__(self,df:pd.DataFrame,transforms=None,train_mode:bool=True):\n",
    "    self.df = df\n",
    "    self.transforms = transforms\n",
    "    self.train_mode = train_mode\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self,idx):\n",
    "    lr_path = self.df['LR'].iloc[idx]\n",
    "    lr_img = cv2.imread(lr_path)\n",
    "    # 이미지를 크기변경할때 보간법을 사용\n",
    "    # INTER_CUBIC : 3차(큐빅)보간법 주변 16개의 픽셀 값을 이용해서 부드럽고 자연스러운 확대 이미지를 생성\n",
    "    # MASTER : 가장가까운 이웃, LINEAR(선형보간)\n",
    "    try:\n",
    "      lr_img = cv2.resize(lr_img, (IMG_SIZE,IMG_SIZE),interpolation=cv2.INTER_CUBIC)\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      print(lr_path)\n",
    "    if self.train_mode:\n",
    "      hr_path = self.df['HR'].iloc[idx]\n",
    "      hr_img = cv2.imread(hr_path)\n",
    "      if self.transforms:\n",
    "        transformed = self.transforms(image=lr_img,label=hr_img)\n",
    "        lr_img = transformed['image'] / 255.\n",
    "        hr_img = transformed['label'] / 255.\n",
    "        return lr_img, hr_img\n",
    "    else:\n",
    "      file_name = lr_path.split('/')[-1]\n",
    "      if self.transforms:\n",
    "        transformed = self.transforms(image=lr_img)\n",
    "        lr_img = transformed['image'] / 255.\n",
    "      return lr_img, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "IOwFttdd5DSD"
   },
   "outputs": [],
   "source": [
    "# 데이터 증강 함수  파이프라인에 사용\n",
    "def get_train_transforms():\n",
    "  return A.Compose([\n",
    "      ToTensorV2(p=1.0)],\n",
    "      additional_targets={'image':'image','label':'image'}\n",
    "  )\n",
    "  def get_test_transforms():\n",
    "    return A.Compose([\n",
    "      ToTensorV2(p=1.0)],\n",
    "      additional_targets={'image':'image','label':'image'}\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "3q-Zohk_5nd7"
   },
   "outputs": [],
   "source": [
    "train_dataset = SRDataset(train_df,get_train_transforms(),True)\n",
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "test_dataset = SRDataset(test_df,get_train_transforms(),True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "O5EKVmtD6fel"
   },
   "outputs": [],
   "source": [
    "# ex 입력 3,H,W\n",
    "class SRCNN(nn.Module):\n",
    "  def __init__(self,num_channels=3,feature_dim = 64,map_dim=32):\n",
    "    '''\n",
    "    feature_dim   첫번째 레이어의 출력수\n",
    "    map_dim       두번째 레이어의 출력수\n",
    "    '''\n",
    "    super(SRCNN,self).__init__()\n",
    "    # 특징추출\n",
    "    # 스트라이드 1이고 패딩이 kernel_size // 2 형태면 해상도 유지\n",
    "    self.features = nn.Sequential(\n",
    "        nn.Conv2d(num_channels,feature_dim,kernel_size=9,stride=1,padding=4),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    #특징맵을 더 압축해서 중요한 정보만 남김\n",
    "    self.map = nn.Sequential(\n",
    "        nn.Conv2d(feature_dim,map_dim,kernel_size=5,stride=1,padding=2),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    # 고해상도 이미지 복원\n",
    "    self.reconstruction = nn.Conv2d(map_dim,num_channels,kernel_size=5,stride=1,padding=2)\n",
    "  def forward(self,x):\n",
    "    x = self.features(x)\n",
    "    x = self.map(x)\n",
    "    x = self.reconstruction(x)\n",
    "    return x\n",
    "  # SRCNN 논문기반으로 가중치 초기화 함수 제작\n",
    "  # 적절할 가중치 분포를 갖도록 다양한 기법이 존재\n",
    "  # 1. 공통 conv레이어 초기화\n",
    "  # 2. 마지막 레이어는 별도 초기화 : 출력이 이미지복원->작은변화에도 민감하게 반응하기 위해서\n",
    "  def _initialize_weights(self)->None:\n",
    "    #1\n",
    "    for module in self.modules():\n",
    "      if isinstance(module,nn.Conv2d):\n",
    "        nn.init.normal_(module.weight.data,\n",
    "                        0.0,\n",
    "                        # 각 층의 출력분산이 적절하게 유지할수 있도록\n",
    "                        math.sqrt(2./(module.out_channels*module.weight.data[0][0].numel())))\n",
    "        if module.bias is not None:\n",
    "          nn.init.zeros_(module.bias)\n",
    "    #2\n",
    "    nn.init.normal_(self.reconstruction.weight.data,0.0,0.001)\n",
    "    nn.init.zeros_(self.reconstruction.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IHAkc4jZkzlo"
   },
   "outputs": [],
   "source": [
    "# gpu 메모리 확보\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Wrg-QCL5Ti78"
   },
   "outputs": [],
   "source": [
    "# 학습함수\n",
    "def train(model,optimizer,train_loader,scheduler,device):\n",
    "  model.to(device)\n",
    "  model.train()\n",
    "  criterion = nn.MSELoss().to(device)\n",
    "  best_model = None\n",
    "  bast_loss = 9999\n",
    "  for epoch in range(1,EPOCHS+1):\n",
    "    train_loss = []\n",
    "    for lr_img, hr_img in tqdm(iter(train_loader)):\n",
    "      lr_img, hr_img = lr_img.float().to(device), hr_img.float().to(device)\n",
    "      optimizer.zero_grad()\n",
    "      #예측\n",
    "      pred_hr_img = model(lr_img)\n",
    "      loss = criterion(pred_hr_img,hr_img)\n",
    "      #역전파\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_loss.append(loss.item())\n",
    "    if scheduler is not None:\n",
    "      scheduler.step()\n",
    "    _train_loss = np.mean(train_loss)\n",
    "    print(f'epoch:{epoch} train_loss:{_train_loss:.5f}')\n",
    "    # best_loss = 0.01    _train_loss =. 0.005\n",
    "    if best_loss > _train_loss:\n",
    "      best_loss = _train_loss\n",
    "      best_model = model\n",
    "  return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515,
     "referenced_widgets": [
      "bc69add0fc454d869c88e27bf05e287d",
      "67e4bb47a5194cf7bfe8f913f2920603",
      "ed19b33d91494e0fb484575e082cc1d8",
      "1a9b65fa9e8f46f1800b88226c9dd779",
      "be0b4e93c4c748adb78feeb85cec1061",
      "c44bc32a8bc644a881fea70b470b1b0c",
      "4ee148d356e944a8971a1fc906655c47",
      "ce48009ecddf4e5a91d98cb7225783ef",
      "3b6435acd847466a9b970b0adbd091d4",
      "37a7284a0a2b4d589a19ff9f56582274",
      "f8a9631d31484cfc9fe882d6c00f3fc2"
     ]
    },
    "id": "ruIkQXOWVOWX",
    "outputId": "ee128606-7967-41f1-ae80-975afba9a5b4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c10710846634b7892f1d42631b5fcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacity of 19.70 GiB of which 412.88 MiB is free. Process 3160497 has 19.29 GiB memory in use. Of the allocated memory 19.08 GiB is allocated by PyTorch, and 1.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 5에포크마다 학습률을 0.5씩 감소\u001b[39;00m\n\u001b[32m      6\u001b[39m scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=\u001b[32m5\u001b[39m,gamma=\u001b[32m0.5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m trained_model = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, train_loader, scheduler, device)\u001b[39m\n\u001b[32m     15\u001b[39m loss = criterion(pred_hr_img,hr_img)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#역전파\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     19\u001b[39m train_loss.append(loss.item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 5.50 GiB. GPU 0 has a total capacity of 19.70 GiB of which 412.88 MiB is free. Process 3160497 has 19.29 GiB memory in use. Of the allocated memory 19.08 GiB is allocated by PyTorch, and 1.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 모델객체 생성\n",
    "model = nn.DataParallel(SRCNN())\n",
    "model.eval()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=LEARING_RATE)\n",
    "# 5에포크마다 학습률을 0.5씩 감소\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=5,gamma=0.5)\n",
    "trained_model = train(model,optimizer,train_loader,scheduler,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrG6GV05X6F2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1a9b65fa9e8f46f1800b88226c9dd779": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37a7284a0a2b4d589a19ff9f56582274",
      "placeholder": "​",
      "style": "IPY_MODEL_f8a9631d31484cfc9fe882d6c00f3fc2",
      "value": " 0/76 [00:05&lt;?, ?it/s]"
     }
    },
    "37a7284a0a2b4d589a19ff9f56582274": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b6435acd847466a9b970b0adbd091d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ee148d356e944a8971a1fc906655c47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67e4bb47a5194cf7bfe8f913f2920603": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c44bc32a8bc644a881fea70b470b1b0c",
      "placeholder": "​",
      "style": "IPY_MODEL_4ee148d356e944a8971a1fc906655c47",
      "value": "  0%"
     }
    },
    "bc69add0fc454d869c88e27bf05e287d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_67e4bb47a5194cf7bfe8f913f2920603",
       "IPY_MODEL_ed19b33d91494e0fb484575e082cc1d8",
       "IPY_MODEL_1a9b65fa9e8f46f1800b88226c9dd779"
      ],
      "layout": "IPY_MODEL_be0b4e93c4c748adb78feeb85cec1061"
     }
    },
    "be0b4e93c4c748adb78feeb85cec1061": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c44bc32a8bc644a881fea70b470b1b0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce48009ecddf4e5a91d98cb7225783ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed19b33d91494e0fb484575e082cc1d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce48009ecddf4e5a91d98cb7225783ef",
      "max": 76,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b6435acd847466a9b970b0adbd091d4",
      "value": 0
     }
    },
    "f8a9631d31484cfc9fe882d6c00f3fc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
